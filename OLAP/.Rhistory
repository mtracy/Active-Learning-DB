neg = read.csv(file="rt-polaritydata/rt-polarity.neg", header=FALSE)
View(neg)
neg = read.text(file="rt-polaritydata/rt-polarity.neg", header=FALSE)
?read
neg = read.table(file="rt-polaritydata/rt-polarity.neg", header=FALSE)
neg = read.delim(file="rt-polaritydata/rt-polarity.neg", header=FALSE)
View(neg)
pos = read.delim(file="rt-polaritydata/rt-polarity.pos", header=FALSE)
neg = read.delim(file="rt-polaritydata/rt-polarity.neg", header=FALSE, stringsAsFactors = FALSE)
pos = read.delim(file="rt-polaritydata/rt-polarity.pos", header=FALSE, stringsAsFactors = FALSE)
text = rbind(neg, pos)
View(pos)
processed = textProcessor(text)
library(stm)
processed = textProcessor(text)
npText = rbind(neg, pos)
processed = textProcessor(npText)
library(lda)
neg = read.delim(file="rt-polaritydata/rt-polarity.neg", header=FALSE, stringsAsFactors = FALSE)
pos = read.delim(file="rt-polaritydata/rt-polarity.pos", header=FALSE, stringsAsFactors = FALSE)
npText = rbind(neg, pos)
>lda
?lda
corpus <- lexicalize(npText, lower=TRUE)
?lexicalize
model = lda.collapsed.gibbs.sampler(corpus$documents, K, corpus$vocab, num.iterations = n)
K = 200
n = 5
model = lda.collapsed.gibbs.sampler(corpus$documents, K, corpus$vocab, num.iterations = n)
alphaV = 0.01
model = lda.collapsed.gibbs.sampler(corpus$documents, K, corpus$vocab, num.iterations = n,
alpha = alphaV)
K = 200
n = 5
alphaV = 0.01
etaV = 0.1
model = lda.collapsed.gibbs.sampler(corpus$documents, K, corpus$vocab, num.iterations = n,
alpha = alphaV, eta = etaV)
tdm = model$topics
View(tdm)
documents = corpus$documents
vocab = corpus$vocab
K <- 200
G <- 10
alpha <- 0.02
eta <- 0.02
fit <- lda.collapsed.gibbs.sampler(documents = documents, K = K, vocab = vocab,
num.iterations = G, alpha = alpha,
eta = eta, initial = NULL, burnin = 0,
compute.log.likelihood = TRUE)
processed = textProcessor(npText)
neg = read.delim(file="rt-polaritydata/rt-polarity.neg", header=FALSE)
processed = textProcessor(neg)
library(lda)
neg = read.delim(file="rt-polaritydata/rt-polarity.neg", header=FALSE, stringsAsFactors = FALSE)
pos = read.delim(file="rt-polaritydata/rt-polarity.pos", header=FALSE, stringsAsFactors = FALSE)
npText = rbind(neg, pos)
out <- prepDocuments(npText, corpus$vocab, lower.thresh = 1)
corpus <- lexicalize(npText, lower=TRUE)
View(npText)
topicModelDF = npText
neg = read.delim(file="rt-polaritydata/rt-polarity.neg", header=FALSE, stringsAsFactors = FALSE)
pos = read.delim(file="rt-polaritydata/rt-polarity.pos", header=FALSE, stringsAsFactors = FALSE)
npText = rbind(neg, pos)
topicModelDF = npText
# pre-processing:
topicModelDF <- gsub("'", "", topicModelDF)  # remove apostrophes
topicModelDF <- gsub("[[:punct:]]", " ", topicModelDF)  # replace punctuation with space
topicModelDF <- gsub("[[:cntrl:]]", " ", topicModelDF)  # replace control characters with space
topicModelDF <- gsub("[[:digit:]]", " ", topicModelDF)  # replace numbers with space
topicModelDF <- gsub("^[[:space:]]+", "", topicModelDF) # remove whitespace at beginning of documents
topicModelDF <- gsub("[[:space:]]+$", "", topicModelDF) # remove whitespace at end of documents
topicModelDF <- tolower(topicModelDF)  # force to lowercase
# tokenize on space and output as a list:
doc.list <- strsplit(topicModelDF, "[[:space:]]+")
# compute the table of terms:
term.table <- table(unlist(doc.list))
term.table <- sort(term.table, decreasing = TRUE)
# remove terms that are stop words or occur fewer than 5 times:
del <- names(term.table) %in% stop_words | term.table < 2
stop_words <- stopwords("SMART")
library(lda)
library(psych)
library(sqldf)
library('NLP')
library('slam')
library('tm')
library('SnowballC')
library('igraph')
library('ggplot2')
stop_words <- stopwords("SMART")
specific_stop_words <- c("pt", "patient", "physician", "nurse", "patients", "order", "orders", "ordered")
stop_words <- c(stop_words, specific_stop_words)
# remove terms that are stop words or occur fewer than 5 times:
del <- names(term.table) %in% stop_words | term.table < 2
term.table <- term.table[!del]
vocab <- names(term.table)
# now put the documents into the format required by the lda package:
get.terms <- function(x) {
index <- match(x, vocab)
index <- index[!is.na(index)]
rbind(as.integer(index - 1), as.integer(rep(1, length(index))))
}
documents <- lapply(doc.list, get.terms)
D <- length(documents)  # number of documents (2079)
W <- length(vocab)  # number of terms in the vocab (3159)
K <- 100
G <- 10
alpha <- 0.02
eta <- 0.02
fit <- lda.collapsed.gibbs.sampler(documents = documents, K = K, vocab = vocab,
num.iterations = G, alpha = alpha,
eta = eta, initial = NULL, burnin = 0,
compute.log.likelihood = TRUE)
documents <- lapply(doc.list, get.terms)
corpus <- lexicalize(npText, lower=TRUE)
documents = corpus$documents
vocab = corpus$vocab
K <- 200
G <- 10
alpha <- 0.02
eta <- 0.02
fit <- lda.collapsed.gibbs.sampler(documents = documents, K = K, vocab = vocab,
num.iterations = G, alpha = alpha,
eta = eta, initial = NULL, burnin = 0,
compute.log.likelihood = TRUE)
theta <- t(apply(fit$document_sums + alpha, 2, function(x) x/sum(x)))
phi <- t(apply(t(fit$topics) + eta, 2, function(x) x/sum(x)))
neg = read.delim(file="rt-polaritydata/rt-polarity.neg", header=FALSE, stringsAsFactors = FALSE)
pos = read.delim(file="rt-polaritydata/rt-polarity.pos", header=FALSE, stringsAsFactors = FALSE)
npText = rbind(neg, pos)
corpus <- lexicalize(npText, lower=TRUE)
documents = corpus$documents
npText = pos
corpus <- lexicalize(npText, lower=TRUE)
documents = corpus$documents
vocab = corpus$vocab
K <- 200
G <- 10
alpha <- 0.02
eta <- 0.02
G <- 5
alpha <- 0.02
eta <- 0.02
fit <- lda.collapsed.gibbs.sampler(documents = documents, K = K, vocab = vocab,
num.iterations = G, alpha = alpha,
eta = eta, initial = NULL, burnin = 0,
compute.log.likelihood = TRUE)
?stm
mod = stm(docs = documents, vocab = vocab, 5)
temp = textProcessor(npText$V1)
vocab = temp$vocab
docs = temp$documents
out = prepDocuments(docs, vocab)
docs = out$documents
vocab = out$vocab
mod.out = stm(docs, vocab, 10, max.em.its = 5)
theta = mod.out$theta
write.csv(theta, file="results/theta.csv", header=FALSE)
write.csv(theta, file="results/theta.csv", col.names = FALSE, row.names = FALSE)
write.csv(theta, file="results/theta.csv", col.names = FALSE, row.names = FALSE)
labels = matrix(0, nrow = 2569, ncol = 1)
labels[1:1678,] = -1
labels[1679:2569,] = 1
View(labels)
write.csv(labels, file="results/labels.csv", row.names = FALSE)
write.csv(theta, file="results/theta.csv", colnames = FALSE, row.names = FALSE)
write.csv(theta, file="results/theta.csv", col.names = FALSE, row.names = FALSE)
write.csv2(theta, file="results/theta.csv", col.names = FALSE, row.names = FALSE)
theta = as.data.frame(theta)
write.csv(theta, file="results/theta.csv", col.names = FALSE, row.names = FALSE)
View(theta)
write.table(theta, file="results/theta.csv", col.names = FALSE, row.names = FALSE, sep=",")
write.table(labels, file="results/labels.csv", col.names = FALSE, row.names = FALSE, sep = ",")
library('stm')
neg = read.delim(file="rt-polaritydata/rt-polarity.neg", header=FALSE, stringsAsFactors = FALSE)
pos = read.delim(file="rt-polaritydata/rt-polarity.pos", header=FALSE, stringsAsFactors = FALSE)
npText = rbind(neg, pos)
temp = textProcessor(npText$V1)
vocab = temp$vocab
docs = temp$documents
out = prepDocuments(docs, vocab)
docs = out$documents
vocab = out$vocab
mod.out = stm(docs, vocab, 100, max.em.its = 100)
theta = mod.out$theta
labels = matrix(0, nrow = 4247, ncol = 1)
labels[1:1679,] = -1
labels[1680:4247,] = 1
write.table(theta, file="results/theta.csv", col.names = FALSE, row.names = FALSE, sep=",")
write.table(labels, file="results/labels.csv", col.names = FALSE, row.names = FALSE, sep = ",")
beta = mod.out$beta
temp = beta$logbeta[1,]
temp = as.matrix(beta$logbeta)
temp[1,]
sort(temp[1,])
sort(temp[1])
sort(temp[1,])
order(temp[1,])
order(temp[1,])
temp[1,1]
order(temp[1,1])
temp[1][1]
tt = temp[1][1]
tt = temp[1]
temp = as.matrix(beta$logbeta)
temp = as.matrix(unlist(beta$logbeta))
temp = as.matrix((beta$logbeta))
temp = as.matrix((beta$logbeta[1]))
dim(temp)
tt = temp[1]
tt = as.matrix(temp[1])
temp(tt)
dim(tt)
labelTopics(mod.out, c(1,2,3))
labelTopics(mod.out)
